##################################################################
### Opportunities to increase pollinator habitat model         ###
### 13 Jan 2025                                                ###
### CSJ                                                        ###
##################################################################
#'
#'
#' Pollination opportunities model
#'
#' @param x A basemap, in a list of sf tiles or as one sf object. Must have attributes "HabCode_B", "HabBroad", "GI".
#' @param studyArea The boundaries of the site, as one sf object. The final raster will be masked to this shape. For best results this shape should be smaller than the basemap (which should be buffered by typically 300 m - 1km to avoid edge effects).
#' @param capacity File path for a pollination capacity raster covering the study area
#' @param demand File path for a pollination demand raster covering the study area
#' @param constraints File path to where constraints are stored
#' @param mask_arable Should arable land be masked out of the opportunities output? Defaults to TRUE.
#' @param projectLog The RDS project log file generated by the wizard app and containing all file paths to data inputs and model parameters
#' @param runtitle A customised title you can give a specific model run, which will be appended to your project title in the outputs. If comparing a basemap to an intervention map, we recommend using "pre" and "post", or a short description of the interventions, e.g. "baseline" vs "tree planting".
#' @param save Path to folder where outputs will be saved. By default a folder will be created using your chosen run title, prefixed by "services_". Do not use this argument unless you need to save the outputs somewhere else.

#'
#' @return raster
#' @export
#'
#'
#'
poll_opps_by_threshold <- function(x = parent.frame()$mm,
                                   studyArea = parent.frame()$studyArea,
                                   capacity = parent.frame()$capacity,
                                   demand = parent.frame()$demand,
                                   ES = NULL,
                                   constraints = parent.frame()$constraints,
                                   mask_arable = TRUE,
                                   name_prefix = NULL,
                                   projectLog = parent.frame()$projectLog,
                                   runtitle = parent.frame()$runtitle,
                                   save = NULL) {
  ## Setup ----

  timeA <- Sys.time() # start time


  # Create output directory automatically if doesn't already exist
  if (is.null(save)) {
    save <- file.path(
      projectLog$projpath,
      paste0("opportunities_", runtitle)
    )

    if (!dir.exists(save)) {
      dir.create(save)
    }
  } else {
    # if user specified their own save directory we check that it's ok
    if (!dir.exists(save) | file.access(save, 2) != 0) {
      stop("Save directory doesn't exist, or you don't have permission to write to it.")
    }
  }

  # Create a temp directory for scratch files

  scratch <- file.path(
    projectLog$projpath,
    "ecoservR_scratch"
  )

  if (!dir.exists(scratch)) {
    dir.create(scratch)
  }

  # if mm is stored in list, combine all before proceeding
  if (isTRUE(class(x) == "list")) {
    x <- do.call(rbind, x) %>% sf::st_as_sf()
    # NOT using rbindlist here because only keeps the extent of the first tile
  }

  # Select land use for constraints -----------------------------------------

  ## We could add/amend as needed, those are places where you would normally not be able to create a new/different habitat. Mostly
  # infrastructure and private property, also includes water.

  # We filter down the mm object

  landuse_constraints <- x %>%
    # left_join(hab_lookup[, c("Ph1code", "HabBroad", "HabClass")],
    #           by = c("HabCode_B" = "Ph1code")
    # ) %>% # join habitat desc
    filter(HabBroad %in% c(
      "Built up areas", # keep land uses that are constraints
      "Pavement",
      "Garden",
      "Roads", "Path",
      "Railway",
      "Water, fresh", # to avoid showing aquatic habitats as suitable for interventions!
      "Water, brackish",
      "Intertidal",
      "Saltmarsh"
    ) | GI %in% c(
      "Playing Field",
      "Bowling Green",
      "Tennis Court",
      "Golf Course",
      "Allotments Or Community Growing Spaces",
      "Private Garden"
    )) %>%
    st_geometry() %>%
    st_as_sf() # drop attributes and make sf df


  # Add arable land as a constraint if arable_mask is set to TRUE

  if (mask_arable == TRUE) {
    arable_mask <- dplyr::filter(x, HabCode_B == "J11") # Create subset of demand habitats (core)
    arable_mask <- st_buffer(arable_mask, -20) %>%
      st_geometry() %>%
      st_as_sf()
  }

  # Import other constraints ------------------------------------------------
  message("Importing other constraints")
  ## NB: When they're spatial files we can use the wkt filter to reduce amount of data imported

  constraints_files <- list.files(constraints,
    pattern = paste0(c(".shp$", ".gpkg$", ".gml$"), collapse = "|"),
    full.names = TRUE,
    recursive = TRUE
  )

  # Import power lines
  power_constraints <- st_read(
    constraints_files[grepl("powerlines", constraints_files)],
    wkt_filter = st_as_text(st_as_sfc(st_bbox(studyArea)))
  ) %>% # OSM power lines
    st_geometry() %>%
    st_as_sf() %>%
    st_transform(27700) %>%
    st_make_valid() %>%
    st_buffer(10) %>%
    st_union()


  # Import HES sites, combine
  heritage_constraints <- rbind(

    # monuments
    st_read(
      constraints_files[grepl("monuments", constraints_files)],
      wkt_filter = st_as_text(st_as_sfc(st_bbox(studyArea)))
    ) %>% # OSM power lines
      st_geometry() %>%
      st_as_sf() %>%
      st_transform(27700) %>%
      st_make_valid(),


    # battlefields
    st_read(
      constraints_files[grepl("battlefield", constraints_files)],
      wkt_filter = st_as_text(st_as_sfc(st_bbox(studyArea)))
    ) %>% # OSM power lines
      st_geometry() %>%
      st_as_sf() %>%
      st_transform(27700)
  ) %>%
    st_buffer(30) %>% # add buffer
    st_union() %>%
    st_make_valid() %>% # union to remove overlaps
    st_geometry() %>%
    st_as_sf() # drop attributes and make sf df


  # Import ancient woodlands
  ancient_woodland_constraints <- st_read(
    constraints_files[grepl("AWI", constraints_files)],
    wkt_filter = st_as_text(st_as_sfc(st_bbox(studyArea)))
  ) %>% # OSM power lines
    st_geometry() %>%
    st_as_sf() %>%
    st_transform(27700) %>%
    st_make_valid() %>%
    st_buffer(30) %>%
    st_union()


  ## we may want other things like
  # peaty locations
  # protected, high-quality habitats (poor quality could actually be an opportunity)
  # ecological/practical suitability constraints like slopes, hydrology, soil type...


  # Capacity and demand maps

  # capacity_map <- rast(capacity)
  # demand_map <- rast(demand)


  # Create raster template --------------------------------------------------

  ## using terra
  r <- rast(ext(demand), # make sure extent of template is same as extent of constraints by assigning extent of our saved rescaled rasters
    resolution = 10
  )
  terra::crs(r) <- "epsg:27700"

  # Rasterise constraints into template --------------------------------------

  ## fasterize doesn't yet accept terra so needs to convert template to raster

  constraints_all <- fasterize(
    do.call(rbind, list(
      landuse_constraints,
      heritage_constraints,
      power_constraints
    )) %>%
      st_cast(to = "MULTIPOLYGON", warn = FALSE) %>% st_cast(to = "POLYGON", warn = FALSE), # need to be single-part to work with fasterize
    raster::raster(r)
  )

  # Apply constraints to maps -----------------------------------------------

  demand <- terra::mask(demand,
    terra::rast(constraints_all),
    inverse = TRUE
  ) # important! We want to EXCLUDE them, not mask our layers to within them

  capacity <- terra::mask(capacity,
    terra::rast(constraints_all),
    inverse = TRUE
  )


  # Generate opportunities (ES) --------------------------------------------------

  ## Threshold demand scores and keep just highest demand

  ## NB: Here, to be very correct, we would instead need to calculate the quantiles at NATIONAL level, but you'd never be able to load
  # all the data to calculate quantiles. Even on a chunk, terra will probably tell you that it's using a random sample of the data.
  # We may need to calculate "meta-quantiles" by calculating the quantiles on each chunk separately, then doing an area-weighted mean
  # to get the average 75% percentile for the country based on the 17 data points...
  # If you do that, remember to first apply the subst() line just below to set 0 demand to NA before you calculate.


  # for demand rasters we reclassify 0 as NA, otherwise very often the desired quantile will be 0!
  # This means we are looking for highest demand ONLY WITHIN AREAS WHERE THERE IS SOME DEMAND.

  demand <- terra::subst(demand, 0, NA)
  #capacity <- terra::subst(capacity, 0, NA)
  
  capacity <- clamp(capacity, 0, 0.5870664, values = F) #limit capacity by 50% quantile (remove top 50%). Quantile taken from separate script

  # calculate quantiles, by layer
  # Qsummary_d <- terra::global(demand, terra::quantile, probs = threshold, na.rm = TRUE)
  # names(Qsummary_d) <- "Q"

  # Qsummary_c <- terra::global(capacity, terra::quantile, probs = 1-threshold, na.rm = TRUE)
  # names(Qsummary_c) <- "Q"


  # now reclassify each raster using the corresponding relevant quantile

  # demand_opps <- mapply(
  #   function(x, q) {
  #     terra::classify(demand[[x]],
  #       rcl = matrix(
  #         c(
  #           -Inf, q, NA,
  #           q, Inf, 1
  #         ),
  #         ncol = 3, byrow = TRUE
  #       ),
  #       include.lowest = TRUE, right = FALSE
  #     )
  #   },
  #   #x = row.names(Qsummary_d),
  #   x=1,
  #   #q = Qsummary_d$Q,
  #   SIMPLIFY = FALSE
  # ) %>% terra::rast()
  #
  # capacity_opps <- mapply(
  #   function(x, q) {
  #     terra::classify(capacity[[x]],
  #                     rcl = matrix(
  #                       c(
  #                         -Inf, q, 1,
  #                         q, Inf, NA
  #                       ),
  #                       ncol = 3, byrow = TRUE
  #                     ),
  #                     include.lowest = TRUE, right = FALSE
  #     )
  #   },
  #   #x = row.names(Qsummary_c),
  #   x=1,
  #   #q = Qsummary_c$Q,
  #   SIMPLIFY = FALSE
  # ) %>% terra::rast()
  #
  #
  #
  #
  # es_opps <- sum(
  #   demand_opps, capacity_opps
  # )

  #### CREATE POLLINATION HABITATS; USE THIS TO MASK OPPS
  edgedist <- 20
  size_threshold <- 0.5
  corehabs <- c(
    "J21", "J22", "J23", "J12v", "Linear",
    "H65", "H66", "H84", "H85",
    "H24", "H26", "H2u"
  )

  ### Create core habitat layer -----
  message("Creating layer of core habitats")

  core <- dplyr::filter(x, HabCode_B %in% corehabs)

  corebuffer <- sf::st_buffer(core, edgedist) %>% sf::st_union()

  ### Create edge habitat layer -----
  message("Creating layer of edge habitats")

  edge <- dplyr::filter(x, grepl("A1", HabCode_B))

  # use buffer around core habitats to clip edge habitats used by pollinators
  edgeclip <- edge[unique(unlist(sf::st_intersects(corebuffer, edge))), ] %>%
    sf::st_intersection(corebuffer) %>%
    sf::st_make_valid() %>%
    st_collection_extract("POLYGON")

  ### Recombine and define habitat patches -----
  pollin_hab <- c(sf::st_geometry(edgeclip), sf::st_geometry(core)) %>%
    sf::st_union() %>%
    sf::st_as_sf() %>%
    sf::st_cast("MULTIPOLYGON") %>%
    sf::st_cast("POLYGON") %>% # explode back to single-part polys to filter out small ones
    mutate(area_ha = as.numeric(st_area(.)) / 10000) %>%
    filter(area_ha > size_threshold)

  #### Stitch together opps

  es_opps <- sum(demand, capacity, na.rm = FALSE)

  if (mask_arable == TRUE) {
    es_opps <- terra::mask(es_opps, arable_mask, inverse = T)
  }

  es_opps <- terra::mask(es_opps, pollin_hab, inverse = T)

  # rescale to 0-1
  es_opps <- terra::classify(es_opps, cbind(0, 10, 1))

  # Save --------------------------------------------------------------------

  terra::writeRaster(es_opps,
    filename = file.path(save, paste0(
      name_prefix, "_", runtitle, "_", ES, "_opps.tif"
    )), overwrite = TRUE
  )
}
