############################################################
### Revised flood mitigation demand - in development     ###
### NatureScot - Flood mitigation                        ###
### Cameron Singh-Johnstone, Rachel Henderson,           ###
### Sandra Angers-Blondin                                ###
### 12-09-2024                                           ###
############################################################

## TODO
# sense check the OSM assets
# add instructions for what to do if any of the risk maps are null
# is it better to take in three separate parameters for flood risk maps, or as a list?

## Indicators:
# Likelihood of flooding: the more often a place floods, the greater the need for mitigation.
# Vulnerability of assets: critical infrastructure has higher scores. (currently focal stats SUM)
# Population density: more populated places have a greater need for mitigation.


#' Flood Risk Mitigation Demand Model
#'
#' Runs the flood mitigation demand model, generating demand scores based on the likelihood of flooding (SEPA), assets at risk of flooding (key infrastructure and agricultural land), and population.

#' @param x A basemap, in a list of sf tiles or as one sf object. Must have attribute HabCode_B.
#' @param studyArea The boundaries of the site, as one sf object. The final raster will be masked to this shape. For best results this shape should be smaller than the basemap (which should be buffered by typically 300 m - 1km to avoid edge effects).
#' @param res Desired resolution of the raster. Default is 10m.
#' @param flood_risk_type List of flood risk types to run the model for; use TRUE to indicate the model should be run for each type of flooding (river, surface, and coastal). A flood risk map must correspond in `risk_maps`
#' @param risk_maps A list of file paths to SEPA geodatabase files containing the flood maps (developed for v2.1). This can be any combination of flooding from rivers, seas, or surface water depending on the event(s) of interest. List the file paths in order of river, surface, and coastal flood maps. Use NULL if a map is not provided.
#' @param local Radius (m) for focal statistics at local range. Default is 300 m.
#' @param pop_threshold Population density (people per hectare) below which to consider there is no demand. Default is 5.
#' @param indicators Logical; should raw indicators (before rescaling) be saved to the project folder? Default TRUE.
#' @param indic_weights A numeric vector of length 3, with weights for flood extent, assets, and population, respectively. Default to c(0.5, 0.25, 0.25) so that population and assets combined has equal weight to flood extent.
#' @param use_osm Use OpenStreetMap to refine the selection of assets at risk? Will query the OSM API for available data on hospitals, schools, and other community places classed as vulnerable by SEPA. Requires an internet connection and `osmdata` package. If FALSE, a coarser ranking is made by extracting infrastructure from the basemap but the function of buildings is unknown.
#' @param custom_ext A custom extent; the extent of the final output will match this extent
#' @param projectLog The RDS project log file generated by the wizard app and containing all file paths to data inputs and model parameters
#' @param runtitle A customised title you can give a specific model run, which will be appended to your project title in the outputs. If comparing a basemap to an intervention map, we recommend using "pre" and "post", or a short description of the interventions, e.g. "baseline" vs "tree planting".
#' @param save Path to folder where outputs will be saved. By default a folder will be created using your chosen run title, prefixed by "services_". Do not use this argument unless you need to save the outputs somewhere else.
#' @return A raster scoring the demand for inland flood regulation on a scale of 0-1
#' @export
#'


demand_flood_inland_scot <- function(x = parent.frame()$mm,
                                     studyArea = parent.frame()$studyArea,
                                     flood_risk_type = c(river = TRUE, surface = TRUE, coastal = TRUE),
                                     risk_maps = c(river = NULL, surface = NULL, coastal = NULL),
                                     local = 300,
                                     pop_threshold = 5,
                                     indicators = TRUE,
                                     indic_weights = c(0.5, 0.25, 0.25),
                                     res = 10,
                                     custom_ext = NULL,
                                     use_osm = FALSE,
                                     projectLog = parent.frame()$projectLog,
                                     runtitle = parent.frame()$runtitle,
                                     save = NULL) {
  # Setup -------------------------------------------------------------------

  timeA <- Sys.time() # start time

  # Create output directory automatically if doesn't already exist
  if (is.null(save)) {
    save <- file.path(
      projectLog$projpath,
      paste0("services_", runtitle)
    )

    if (!dir.exists(save)) {
      dir.create(save)
    }
  } else {
    # if user specified their own save directory we check that it's ok
    if (!dir.exists(save) | file.access(save, 2) != 0) {
      stop("Save directory doesn't exist, or you don't have permission to write to it.")
    }
  }


  # Check risk layer
  # if (is.null(risk_map) || !file.exists(risk_map)) stop("You must provide the SEPA risk layer.")

  # Is the indicator argument an expected value (TRUE or FALSE)?
  if (!is.logical(indicators)) {
    warning("indicators argument must be TRUE or FALSE; using TRUE by default")
    indicators <- TRUE
  }

  # Set (and create if needed) the indicator folder
  if (indicators) {
    indicator_path <- file.path(save, "indicators") # set the indicator path

    if (!dir.exists(indicator_path)) {
      dir.create(indicator_path)
    }
  }

  # Warning and resulting to default if weights entered incorrectly
  try(if (length(indic_weights) != 3 | !is.numeric(indic_weights)) {
    warning("Weights must be a numeric vector of length 3 for this model. Using the default (flood extent: 0.5, asset vulnerability: 0.25, and population: 0.25). Specify a weight of 0 if you want to ignore a dataset.", call. = FALSE)
    indic_weights <- c(0.5, 0.25, 0.25)
  })

  # Are the weights specified correctly?
  if (is.numeric(indic_weights)) {
    if (length(indic_weights) != 3) {
      message("Weights should have 3 values for this model. Defaulting to weights of c(0.5, 0.25, 0.25).")
      indic_weights <- c(0.5, 0.25, 0.25)
    }
  } else {
    stop("Weights must be a numeric vector of length 3 for this model. Please refer to documentation. Specify a weight of 0 if you want to ignore a dataset.")
  }


  # Create a temp directory for scratch files

  scratch <- file.path(
    projectLog$projpath,
    "ecoservR_scratch"
  )

  if (!dir.exists(scratch)) {
    dir.create(scratch)
  }

  # if mm is stored in list, combine all before proceeding
  if (isTRUE(class(x) == "list")) {
    message("Recombining basemap tiles")
    x <- do.call(rbind, x) %>% sf::st_as_sf()
  }

  # drop attributes we don't need and join HabBroad
  x <- x %>% dplyr::select(HabCode_B, Theme, Term, GI, corine, housePop)
  x <- dplyr::left_join(x, hab_lookup[c("Ph1code", "HabBroad")],
    by = c("HabCode_B" = "Ph1code")
  )

  ### Create raster template with same properties as mastermap -----
  # starting with a raster package raster, as fasterize won't take anything else
  if (is.null(custom_ext)) {
    x1 <- raster::extent(x)
  } else {
    x1 <- raster::extent(custom_ext)
  }
  r <- raster::raster(x1, res = res, crs = sf::st_crs(x)$wkt)

  # INDICATOR flood extent ----------------------------------------------------

  if (indic_weights[1] > 0) { # only if user wants this indicator

    ## Sum the SEPA flood risk map extents (low, medium, high likelihood) into one raster
    ## The result is a raster that scores 0-3 on flood likelihood

    flood_risk_types <- vector("list", 3)

    for (i in 1:length(flood_risk_type)) {
      risk_type <- names(flood_risk_type[i])

      risk_layers <- sf::st_layers(risk_maps[i])
      # auto-find the layers
      risk_layers <- risk_layers$name[grepl(paste(c("extent_l$", "extent_m$", "extent_h$"), collapse = "|"), risk_layers$name, ignore.case = TRUE)]
      risk_check <- all(grepl(
        paste0(c("H", "M", "L"), collapse = "|"),
        substr(risk_layers, nchar(risk_layers), nchar(risk_layers))
      )) # is each layer name terminating by the likelihood (high/medium/low) of flooding?

      if (!risk_check) stop("Could not auto-detect the flooding layers that correspond to high/medium/low likelihood of flood extent.")

      ## Import them using a spatial query
      floodrisk <- lapply(risk_layers, function(l) {
        sf::st_read(risk_maps[i],
          layer = l,
          wkt_filter = sf::st_as_text(sf::st_geometry(studyArea))
        ) %>%
          mutate(risk_points = 1) %>% # add a point for each polygon; overlapping areas will sum up to greater risk
          dplyr::select(risk_points) %>% # and keep just that
          st_cast("MULTIPOLYGON", warn = FALSE) %>%
          st_cast("POLYGON", warn = FALSE) # required for fasterize
      })


      ## Rasterize the flood and sum them
      # TODO this can get bulky as it's 3 rasters at once - maybe need to write a memory-safe way to do this with temp files on disk

      flood_r <- lapply(floodrisk, function(x) {
        fasterize::fasterize(x, r, field = "risk_points")
      }) %>%
        raster::stack(.) %>%
        sum(na.rm = TRUE)


      rm(floodrisk)
      gc()


      message("Measuring flood risk in ", local, " m radius")
      ## Run through focal stats to smooth
      flood_r <- focalScore(flood_r, radius = local, type = "sum")

      flood_r <- flood_r


      # Might have lost projection so set it
      terra::set.crs(flood_r, sf::st_crs(x)$wkt)



      # Save raw indicator if need be

      if (indicators) {
        raster::writeRaster(flood_r, file.path(
          indicator_path, # we define the path
          paste(projectLog$title, runtitle, paste0(risk_type, "_flood_risk_indic.tif"), sep = "_")
        ),
        overwrite = TRUE
        )
      }

      flood_risk_types[[i]] <- flood_r
    }

    names(flood_risk_types) <- names(flood_risk_type)
  } else {
    flood_r <- r
  }

  # INDICATOR assets at risk --------------------------------------------------

  if (indic_weights[2] > 0) { # only if user wants this indicator

    ## This is land and infrastructure we most care about. The ranking is based on SEPA's Flood Risk and Land Use Vulnerability Guidance. A basic version of the layer is made from the basemap only. This is quite coarse as the basemap doesn't resolve buildings down to their use so we can't set apart hospitals, dwellings, shops, etc. But it is a first pass and we rely on it especially to grab agricultural land, forestry, and the road and rail network. In a second, optional stage, we can use OSM data to refine the ranking.

    message("Creating assets at risk indicator")

    ## create the habitat subset from basemap
    assets <- dplyr::filter(x, Theme %in% c(
      "Buildings",
      "Rail",
      "Roads Tracks And Paths",
      "Roads Tracks And Paths,Structures",
      "Structures",
      "Buildings,Structures",
      "Buildings,Roads Tracks And Paths",
      "Land,Rail",
      "Rail,Structures",
      "Buildings,Rail",
      "Rail,Roads Tracks And Paths",
      "Land,Rail,Structures",
      "Land,Structures",
      "Land,Roads Tracks And Paths,Structures",
      "Roads Tracks And Paths,Rail"
    ) | HabCode_B %in% c(
      "B4", "J11", "J11a", "B4/J11", "J360", "I24",
      "J34", "J362", "A112o", "A112o_T", "A11-O", "J11/Bu"
    ) |
      GI %in% c(
        "School Grounds", "Camping Or Caravan Park",
        "Institutional Grounds"
      ) |
      Term %in% c(
        "Wind Turbine", "Mineral Workings", "Electricity Sub Station",
        "Mineral Workings (Inactive),Rough Grassland",
        "Mineral Workings (Inactive)", "Mineral Workings (Inactive),Rough Grassland,Scrub",
        "Spoil Heap", "Spoil Heap (Inactive)", "Mineral Workings (Inactive),Scrub",
        "Telecommunications Mast", "Footbridge,Step", "Bridge,Step", "Landfill",
        "Rough Grassland,Scrub,Spoil Heap (Inactive)", "Rail Signal Gantry",
        "Upper Level Of Communication", "Mast", "Scrub,Slag Heap (Inactive)",
        "Landfill (Inactive)", "Emergency Telephone", "Slag Heap"
      )) %>% # Add further categories here if desired

      # assign scores
      dplyr::mutate(score = case_when(

        # Highly vulnerable (score 3): domestic buildings, landfill, camping and caravan sites, schools and institutions
        HabCode_B %in% c("J360", "I24", "J34") ~ 3,
        GI %in% c(
          "School Grounds", "Camping Or Caravan Park",
          "Institutional Grounds"
        ) ~ 3,
        Term %in% c("Landfill", "Landfill (Inactive)") ~ 3,

        # Least vulnerable (score 2): all commercial things - our basemap doesn't do well at separating dwellings from shops
        # land and buildings for agriculture and forestry
        HabCode_B %in% c("B4", "J11", "J11a", "B4/J11", "J362", "A112o", "A112o_T", "A11-O", "J11/Bu") ~ 2,

        # Essential (score 1): road/rail network
        Theme %in% c(
          "Rail",
          "Roads Tracks And Paths",
          "Roads Tracks And Paths,Structures",
          "Land,Rail",
          "Rail,Structures",
          "Buildings,Rail",
          "Rail,Roads Tracks And Paths",
          "Land,Rail,Structures",
          "Land,Structures",
          "Land,Roads Tracks And Paths,Structures",
          "Roads Tracks And Paths,Rail"
        ) | Term %in% c(
          "Wind Turbine",
          "Electricity Sub Station",
          "Telecommunications Mast",
          "Footbridge,Step", "Bridge,Step",
          "Rail Signal Gantry",
          "Upper Level Of Communication",
          "Mast", "Emergency Telephone"
        ) ~ 1,


        # Rest we let score 2
        TRUE ~ 2
      ))


    ### OSM DATA WORKFLOW --- --- -- --- --
    ## supplement above asset ranking with Open Street Map data if desired
    if (use_osm) {
      message("Extracting assets from OpenStreetMap for your study area")

      # prep bounding box for query to mimic what you'd get with osmdata::getbb. Must be WGS84 and end up as ymin, xmin, ymax, xmax after passing through opq()
      aoi_box <- sf::st_bbox(sf::st_transform(studyArea, 4326)) %>%
        matrix(byrow = TRUE, ncol = 2)

      # send the queries by degree of vulnerability (TODO: review, sense-check and refine - do points add more locations?)

      vuln_max <- aoi_box %>%
        osmdata::opq() %>%
        osmdata::add_osm_features(list(
          "amenity" = "hospital",
          "amenity" = "school",
          "amenity" = "college",
          "amenity" = "university",
          "amenity" = "kindergarten",
          "amenity" = "fire_station",
          "amenity" = "police",
          "amenity" = "ambulance_station",
          "amenity" = "prison",
          "social_facility" = "nursing_home",
          "social_facility" = "group_home",
          "social_facility" = "hospice"
        )) %>%
        osmdata::osmdata_sf()

      vuln_max <- vuln_max$osm_polygons %>% # retain just polygons
        dplyr::mutate(score = 4) %>% # assign score
        dplyr::select(score)

      # Excluding domestic buildings as we have those from basemap
      vuln_high <- aoi_box %>%
        osmdata::opq() %>%
        osmdata::add_osm_features(list(
          "amenity" = "doctors",
          # "amenity" = "dentist",
          "amenity" = "clinic",
          "landuse" = "landfill",
          "tourism" = "hotel",
          "tourism" = "hostel",
          "building" = "dormitory",
          "social_facility" = "assisted_living",
          "social_facility" = "shelter",
          "social_facility" = "day_care"
        )) %>%
        osmdata::osmdata_sf()

      vuln_high <- vuln_high$osm_polygons %>%
        dplyr::mutate(score = 3) %>%
        dplyr::select(score)

      # Should we extract all the shops etc? Most of those must be classified domestic in our basemap but it would be A LOT of data and could lead to timeouts and issues.
      vuln_least <- aoi_box %>%
        osmdata::opq() %>%
        osmdata::add_osm_features(list(
          "amenity" = "waste_transfer_station"
        )) %>%
        osmdata::osmdata_sf()

      vuln_least <- vuln_least$osm_polygons %>%
        dplyr::mutate(score = 2) %>%
        dplyr::select(score)


      ## Combine
      vuln_osm <- list(vuln_max, vuln_high, vuln_least) %>%
        do.call(rbind, .)

      if (attr(vuln_osm, "sf_column") != attr(assets, "sf_column")) {
        # rename geom col if they don't match
        vuln_osm <- rename_geometry(vuln_osm, attr(assets, "sf_column"))
      }

      assets <- rbind(
        assets %>% dplyr::select(score),
        vuln_osm %>% st_transform(st_crs(assets)) %>% dplyr::select(score)
      )
    } # end of optional OSM workflow


    assets <- assets %>%
      dplyr::arrange(score) # ensure that highest scores get priority in fasterize

    assets_r <- fasterize::fasterize(assets, r, field = "score")

    message("Summarising asset vulnerability in ", local, " m radius")
    # Smooth through the focal function
    assets_r <- focalScore(assets_r, radius = local, type = "sum") 

    # Save raw indicator if need be

    if (indicators) {
      raster::writeRaster(assets_r, file.path(
        indicator_path, # we define the path
        paste(projectLog$title, runtitle, "asset_vuln_indic.tif", sep = "_")
      ),
      overwrite = TRUE
      )
    }
  } else {
    assets_r <- r
  }


  # INDICATOR Population ----------------------------------------------------

  if (indic_weights[3] > 0) { # only if user wants this indicator

    # Population size (sum) within local search distance
    # NOTE - Higher population scores mean there is more societal need

    message("Creating population indicator")

    # Create the spatial points with socioeconomic data for each household
    # We can't go straight from polygon to raster, because then a big house that spans two raster cells would
    # have its population counted twice. By converting to points first, we make sure that each house is only represented once. If more than house house falls within a raster cell, their population gets summed.

    houses <- dplyr::filter(x, HabCode_B == "J360") %>% # filter houses from basemap
      checkgeometry("POLYGON") %>% # need to be single-part before converting to centro
      sf::st_centroid() # get the centroid of each house


    ## Create the population raster by summing individual house populations in each cell
    if (any(!is.na(x$housePop))) {
      population <- raster::rasterize(houses, r,
        field = "housePop", fun = "sum", na.rm = TRUE
      )





      # Focal stats (sum)
      message("...calculating population in ", local, " m radius")

      popscore <- focalScore(population, radius = local, type = "sum") 
    } else {
      popscore <- r
    }

    # Save raw indicator if need be

    if (indicators) {
      raster::writeRaster(popscore, file.path(
        indicator_path, # we define the path
        paste(projectLog$title, runtitle, "population_indic.tif", sep = "_")
      ),
      overwrite = TRUE
      )
    }
  } else {
    popscore <- r
  }

  # Rescale and combine indicators ------------------------------------------------------

  message("Combining indicators")

  ## Mask out areas of low population and rescale
  fw <- raster::focalWeight(r, local, "circle")
  pop_density <- pop_threshold * length(fw[fw > 0]) * res^2 / 10000

  if (hasValues(popscore)) {
    popscore2 <- rescale_score(popscore, minval = pop_density, score_type = "pop")
  } else {
    popscore2 <- terra::classify(rast(popscore), cbind(NA, 0))
  }

  ## Rescale other indicators
  if(use_osm==TRUE){
    assets_r <- assets_r / (length(fw[fw > 0]) * 4) # divide by max if every cell in fw had top score
  }else{
    assets_r <- assets_r / (length(fw[fw > 0]) * 3) # divide by max if every cell in fw had top score
  }
  
  # flood_r <- flood_r / (length(fw[fw > 0]) * 3) # divide by max if every cell in fw had top score

  flood_river_r <- flood_risk_types$river / (length(fw[fw > 0]) * 3)
  flood_surface_r <- flood_risk_types$surface / (length(fw[fw > 0]) * 3)
  flood_coastal_r <- flood_risk_types$coastal / (length(fw[fw > 0]) * 3)


  ## Combine all indicators
  # TODO would be better to allow weights in the model and the final calculation could be a weighted mean
  #  final <- sum(
  #    indic_weights[1] * flood_r,
  #    indic_weights[2] * assets_r,
  #    indic_weights[3] * popscore2,
  #    na.rm = TRUE # important otherwise only gives raster for where all 3 indicators have values
  #  )

  final_river <- sum(
    indic_weights[1] * flood_river_r,
    indic_weights[2] * assets_r,
    indic_weights[3] * popscore2,
    na.rm = TRUE # important otherwise only gives raster for where all 3 indicators have values
  )

  final_surface <- sum(
    indic_weights[1] * flood_surface_r,
    indic_weights[2] * assets_r,
    indic_weights[3] * popscore2,
    na.rm = TRUE # important otherwise only gives raster for where all 3 indicators have values
  )

  final_coastal <- sum(
    indic_weights[1] * flood_coastal_r,
    indic_weights[2] * assets_r,
    indic_weights[3] * popscore2,
    na.rm = TRUE # important otherwise only gives raster for where all 3 indicators have values
  )


  # Save map ----------------------------------------------------------------


  message("Saving final inland flood regulation demand map.")

  #  final <- terra::writeRaster(
  #    terra::mask(final, terra::vect(studyArea)),
  #    filename = file.path(save, paste(projectLog$title, runtitle, "inlandFlood_demand.tif", sep = "_")),
  #    overwrite = TRUE # perhaps not desirable but for now prevents error messages
  #  )

  final_river <- terra::writeRaster(
    terra::mask(final_river, terra::vect(studyArea)),
    filename = file.path(save, paste(projectLog$title, runtitle, "river_inlandFlood_demand.tif", sep = "_")),
    overwrite = TRUE # perhaps not desirable but for now prevents error messages
  )

  final_surface <- terra::writeRaster(
    terra::mask(final_surface, terra::vect(studyArea)),
    filename = file.path(save, paste(projectLog$title, runtitle, "surface_inlandFlood_demand.tif", sep = "_")),
    overwrite = TRUE # perhaps not desirable but for now prevents error messages
  )

  final_coastal <- terra::writeRaster(
    terra::mask(final_coastal, terra::vect(studyArea)),
    filename = file.path(save, paste(projectLog$title, runtitle, "coastal_inlandFlood_demand.tif", sep = "_")),
    overwrite = TRUE # perhaps not desirable but for now prevents error messages
  )


  timeB <- Sys.time() # stop time

  # write performance to log
  projectLog$performance[["dem_inlandFlood"]] <- as.numeric(difftime(
    timeB, timeA,
    units = "mins"
  ))


  updateProjectLog(projectLog) # save revised log

  # Delete all the stuff we don't need anymore

  on.exit({
    rm()
    cleanUp(scratch)
    message("Inland flood mitigation demand model finished. Process took ", round(difftime(timeB, timeA, units = "mins"), digits = 1), " minutes. Please check output folder for your maps.")
  })

  return({
    ## returns the objects in the global environment
    invisible({
      projectLog <<- projectLog
    })
  })
}
